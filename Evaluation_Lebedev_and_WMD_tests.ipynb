{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (Lebedev dataset), tests on WMD similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import functions as f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('/Users/nikolaevaanna/Downloads/187/model.model')\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лебедев texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bipartite + Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_candidates = [round(i,2) for i in list(0.01 * np.arange(100, 270, 20))]\n",
    "tau_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_dict_pk = {i:[] for i in tau_candidates}\n",
    "tau_dict_windowdiff = {i:[] for i in tau_candidates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_paths = sorted([\"texts/lebedev/\" + i for i in os.listdir(\"texts/lebedev\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texts/lebedev/01.txt',\n",
       " 'texts/lebedev/02.txt',\n",
       " 'texts/lebedev/03.txt',\n",
       " 'texts/lebedev/04.txt',\n",
       " 'texts/lebedev/05.txt',\n",
       " 'texts/lebedev/06.txt',\n",
       " 'texts/lebedev/07.txt']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding optimal tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347ed427eb6745b6b516cd82d75d4204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing sentences\n",
      "10 7\n",
      "Lemmatizing sentences\n",
      "10 8\n",
      "Lemmatizing sentences\n",
      "10 12\n",
      "Lemmatizing sentences\n",
      "10 15\n",
      "Lemmatizing sentences\n",
      "10 18\n",
      "Lemmatizing sentences\n",
      "10 18\n",
      "Lemmatizing sentences\n",
      "10 25\n",
      "Lemmatizing sentences\n",
      "10 26\n",
      "Lemmatizing sentences\n",
      "10 28\n",
      "Lemmatizing sentences\n",
      "7 5\n",
      "Lemmatizing sentences\n",
      "7 6\n",
      "Lemmatizing sentences\n",
      "7 7\n",
      "Lemmatizing sentences\n",
      "7 9\n",
      "Lemmatizing sentences\n",
      "7 10\n",
      "Lemmatizing sentences\n",
      "7 13\n",
      "Lemmatizing sentences\n",
      "7 15\n",
      "Lemmatizing sentences\n",
      "7 16\n",
      "Lemmatizing sentences\n",
      "7 16\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 3\n",
      "Lemmatizing sentences\n",
      "7 3\n",
      "Lemmatizing sentences\n",
      "7 5\n",
      "Lemmatizing sentences\n",
      "7 7\n",
      "Lemmatizing sentences\n",
      "7 9\n",
      "Lemmatizing sentences\n",
      "7 12\n",
      "Lemmatizing sentences\n",
      "7 17\n",
      "Lemmatizing sentences\n",
      "7 19\n",
      "Lemmatizing sentences\n",
      "7 4\n",
      "Lemmatizing sentences\n",
      "7 4\n",
      "Lemmatizing sentences\n",
      "7 4\n",
      "Lemmatizing sentences\n",
      "7 5\n",
      "Lemmatizing sentences\n",
      "7 6\n",
      "Lemmatizing sentences\n",
      "7 9\n",
      "Lemmatizing sentences\n",
      "7 12\n",
      "Lemmatizing sentences\n",
      "7 13\n",
      "Lemmatizing sentences\n",
      "7 15\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(text_paths[:-3]):\n",
    "        \n",
    "    for tau in tau_candidates:\n",
    "        \n",
    "        (sents, \n",
    "         real_paragraphs, \n",
    "         pred_segment_indices, \n",
    "         pred_paragraphs) = f.segmentize_bipartite_subgraphs(path, \n",
    "                                                    model=model,\n",
    "                                                    tau=tau,\n",
    "                                                    wmd=False)\n",
    "        \n",
    "        print(len(real_paragraphs), len(pred_segment_indices))\n",
    "        if len(pred_segment_indices) < len(real_paragraphs)/2 or len(pred_segment_indices) > len(real_paragraphs)*2:\n",
    "            continue\n",
    "        \n",
    "        k = round(0.5*len(sents)/len(real_paragraphs))\n",
    "        scores = f.evaluate(f.gold_segment_indices(real_paragraphs), pred_segment_indices, k=k)\n",
    "            \n",
    "        \n",
    "        tau_dict_pk[tau].append(scores[\"pk\"])\n",
    "        tau_dict_windowdiff[tau].append(scores[\"windowdiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.6: [0.32038834951456313,\n",
       "  0.37254901960784315,\n",
       "  0.42592592592592593,\n",
       "  0.6086956521739131],\n",
       " 1.8: [0.39805825242718446,\n",
       "  0.35294117647058826,\n",
       "  0.5370370370370371,\n",
       "  0.5434782608695652],\n",
       " 2.0: [0.4174757281553398,\n",
       "  0.29411764705882354,\n",
       "  0.46296296296296297,\n",
       "  0.43478260869565216]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_dict_pk_short = {k:v for k,v in tau_dict_pk.items() if len(v) == 4}\n",
    "tau_dict_pk_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.6</th>\n",
       "      <th>1.8</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.417476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.462963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1.6       1.8       2.0\n",
       "0  0.320388  0.398058  0.417476\n",
       "1  0.372549  0.352941  0.294118\n",
       "2  0.425926  0.537037  0.462963\n",
       "3  0.608696  0.543478  0.434783"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tau_dict_pk_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.6: 0.4318897368055613, 1.8: 0.45787868170109375, 2.0: 0.4023347367181946}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_dict_pk_mean = {k:np.mean(v) for k,v in tau_dict_pk_short.items()}\n",
    "tau_dict_pk_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pk the best tau is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.6</th>\n",
       "      <th>1.8</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.582524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.431373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1.6       1.8       2.0\n",
       "0  0.475728  0.563107  0.582524\n",
       "1  0.431373  0.411765  0.431373\n",
       "2  0.462963  0.574074  0.555556\n",
       "3  0.652174  0.586957  0.543478"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_dict_windowdiff_short = {k:v for k,v in tau_dict_windowdiff.items() if len(v) == 4}\n",
    "pd.DataFrame(tau_dict_windowdiff_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.6: 0.5055593950914637, 1.8: 0.5339755244530155, 2.0: 0.5282326593223472}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:np.mean(v) for k,v in tau_dict_windowdiff_short.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for windowdiff the best tau is 1.6\n",
    "# let tau be 1.8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408a3c728f26453381a9ed3efc22f885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing sentences\n",
      "12 12\n",
      "Lemmatizing sentences\n",
      "9 15\n",
      "Lemmatizing sentences\n",
      "8 5\n"
     ]
    }
   ],
   "source": [
    "all_scores = {\"pk\":[], \"windowdiff\":[]}\n",
    "real_pars = []\n",
    "pred_pars = []\n",
    "\n",
    "\n",
    "for path in tqdm(text_paths[-3:]):\n",
    "        \n",
    "    (sents, \n",
    "         real_paragraphs, \n",
    "         pred_segment_indices, \n",
    "         pred_paragraphs) = f.segmentize_bipartite_subgraphs(path, \n",
    "                                                    model=model,\n",
    "                                                    tau=tau,\n",
    "                                                    wmd=False)\n",
    "        \n",
    "    print(len(real_paragraphs), len(pred_segment_indices))\n",
    "        \n",
    "    k = round(0.5*len(sents)/len(real_paragraphs))\n",
    "    scores = f.evaluate(f.gold_segment_indices(real_paragraphs), pred_segment_indices, k=k)     \n",
    "    \n",
    "        \n",
    "    all_scores[\"pk\"].append(scores[\"pk\"])\n",
    "    all_scores[\"windowdiff\"].append(scores[\"windowdiff\"])\n",
    "    \n",
    "    real_pars.append(real_paragraphs)\n",
    "    pred_pars.append(pred_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pk': [0.5108695652173914, 0.6263736263736264, 0.35185185185185186],\n",
       " 'windowdiff': [0.5217391304347826, 0.7032967032967034, 0.37037037037037035]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49636501448095655"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores[\"pk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5318020680339521"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores[\"windowdiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['В Австрии есть прекрасный старинный замок на скале - Хохостервиц, про который существует не менее древняя легенда.',\n",
       "  'Войска под предводительством Маргариты Маульташ (типа самой уродливой женщины всех времен и народов) осадили замок.'],\n",
       " ['Решили брать измором, но стояли так долго, что начали голодать сами.',\n",
       "  'В последний момент комендант замка решил нафаршировать остатками зерна последнюю корову и катапультировать ее на врага.',\n",
       "  'Это была последняя еда оборонявшихся.',\n",
       "  'Голодные нападавшие решили, что раз у народа в осаде так много жратвы, то дальше стоять нет смысла и съебались.',\n",
       "  'Кажется, что это управленческий парадокс - выкинуть последнюю еду, когда пиздец нечего есть.',\n",
       "  'Но мораль простая: когда нечего терять - блефуй.',\n",
       "  'Очень интересно в языке устроено разделение на важное и ничтожное.',\n",
       "  'Важное - большое или высокое.',\n",
       "  'Ничтожное - маленькое или низкое.',\n",
       "  'Вершина власти.'],\n",
       " ['Унижаться.', 'С высоты положения.'],\n",
       " ['Низко упасть.', 'Возвеличивать правителя.', 'Принижать достоинства.'],\n",
       " ['Сидеть на Олимпе.'],\n",
       " ['Социальное дно.',\n",
       "  'Высший свет.',\n",
       "  'У нас в школе на стене кабинета литературы висели портреты великих писателей.',\n",
       "  'Пушкин был первым и на 20 сантиметров выше, чтобы обозначить свою особую важность.',\n",
       "  'Исторически правитель сидел на троне (штоб выше остальных), а просители кланялись или просто падали ниц, чтобы показать дополнительно, что они даже не пытаются претендовать на равенство.',\n",
       "  'Ваше высокоблагородие, мы люди маленькие.',\n",
       "  'Нижайше просим ваше высочество.',\n",
       "  'У людей очень плохой интерфейс между фантазиями и реальностью.',\n",
       "  'В этом главная проблема любого творца - как сделать так, чтобы фантазия перешла в реальность при помощи творческих приемов.',\n",
       "  'Потому что без помощи творческих приемов нихуя не получится, никакая фантазия ничего не будет значить для других людей.',\n",
       "  'Чтобы фантазия заработала, ее нужно понятно сформулировать.',\n",
       "  'Это относится совершенно ко всему - от эротической фантазии до идеи сценариста.',\n",
       "  'Как перенести мысль из головы автора к зрителям, слушателям и читателям?',\n",
       "  'Это и есть основная задача любого творчества.'],\n",
       " ['Кстати, именно на этом заваливаются все начинающие фотографы.',\n",
       "  'Они принимают свой кайф от сцены за картинку, которую увидит зритель.',\n",
       "  'А зритель не слышит звуков, не знает контекст, не чувствует температуры, не ценит обстановку, не видит движения.'],\n",
       " ['Поэтому ему похуй на самый лучший на свете закат, потому что на фотке какое-то унылое говно, а не самый лучший закат.'],\n",
       " ['А начинающий фотограф не понимает, что видит зритель, потому что он находится во власти своих фантазий и ощущений, но не умеет их передать.',\n",
       "  'Короче, любой творец ценен своим умением передавать мысли, а не самими мыслями.',\n",
       "  'В Америке страшно дико стали популярны подкасты.',\n",
       "  'Какие-то просто невероятные часы прослушиваний подкастов у среднего американца.',\n",
       "  'Казалось бы, есть радио, есть аудиокниги, есть ютюб на фоне, но американцы слушают подкасты.',\n",
       "  'А у нас не слушают подкасты.',\n",
       "  'Вы можете вспомнить хоть один известный русский подкаст?',\n",
       "  'Или хотя бы неизвестный, но интересный?',\n",
       "  'Когда кто-либо последний раз вам рекомендовал послушать какой-либо подкаст?',\n",
       "  'У меня есть набор базовых установок, которые не меняются уже много десятилетий.',\n",
       "  'Чтобы понять, какая в принципе у меня может быть точка зрения по поводу того или иного вопроса, можно свериться с приведенным ниже списком моих ценностей и позиций.',\n",
       "  'Моя принципы всегда просты: я против любого насилия, против любых убийств, против любых войн, за гармоничное и разностороннее развитие любой личности, за гетеросексуальность с легкими нотками толерантности, за космополитизм с легкими нотками патриотизма, за капитализм, но против корпоративного мудоебства, за просвещенную монархию, за работу с утра до вечера, против пенсий, льгот, нахлебников и бездельников, против популизма.',\n",
       "  'У меня замые замечательные принципы на свете.',\n",
       "  'Если бы все были как я, жизнь была бы еще лучше.',\n",
       "  'Вкус еды и напитков очень сильно зависит от формы посуды.',\n",
       "  'Одна и та же котлета с разных тарелок будет восприниматься по-разному.',\n",
       "  'Еда с деревянной или с фарфоровой тарелки будет иметь разный вкус.',\n",
       "  'Напитки из разных емкостей будут иметь принципиально разный вкус.',\n",
       "  'Если выпить кефир из водочного мерзавчика, он будет одного вкуса, а если из сапога, то совершенно другого.',\n",
       "  'Одно и то же вино из бокалов разной формы будет иметь разный вкус и даже запах (проверьте).',\n",
       "  'Ширина, высота, диаметр, вес, материал посуды - все это имеет огромное влияние на вкус еды и напитков.',\n",
       "  'Мы в школе пили водку из полиэтиленовой обертки от сигаретной пачки, это было омерзительно.',\n",
       "  'Хотя казалось бы - что может испортить водку?',\n",
       "  'Кладбища стремительно теряют свою актуальность.',\n",
       "  'В детстве меня пару раз возили родственники на могилы к предкам.',\n",
       "  'В среднем возрасте я был пару раз на кладбищах, хороня бабушек-дедушек, а так же некоторых друзей и знакомых.',\n",
       "  'Но абсолютно ни разу я не был на какой-либо могиле второй раз.'],\n",
       " ['И не потому что я такая бездушная свинья, а потому что в этом нет никакого смысла.',\n",
       "  'Я помню тех, кто оставил след в моей жизни.',\n",
       "  'Я не помню тех, кто следа не оставил.',\n",
       "  'Поездка к надгробной плите не даст мне ничего, что может дать пересмотр видоса или фоток с ушедшим на тот свет.',\n",
       "  'Думаю, что в будущем никаких кладбищ не будет.',\n",
       "  'Встреча с геометкой места погребения не имеет никакого смысла.',\n",
       "  'Могила - это какой-то лютый архаизм.',\n",
       "  'Раньше я придумывал для себя дизайн могилы, хотел сделать ее интерактивной.',\n",
       "  'Но потом я понял, что лучшая концепция - это развеивание праха на максимально широкой и абстрактной территории.',\n",
       "  'Или я не буду против, если пепел от меня будет использован в качестве удобрения в горшке герани на рандомном подоконнике.'],\n",
       " ['По старой памяти людей еще хоронят на кладбищах или в колумбариях, но смысла в этом больше нет никакого.',\n",
       "  'Что биоразложение, что кремация - одинаково происходят в соответствии с законами физики.',\n",
       "  'Сравнение, как и пример, не являются доказательством в формальной логике.',\n",
       "  'Но разве это ебет обычных людей?',\n",
       "  'Конечно нет.',\n",
       "  'Поэтому сравнение - мощнейший аргумент для доказательства.',\n",
       "  'Например, какая-то жируха скинула балласт, и вешает новые стройные фотки в стиле \"было - стало\".',\n",
       "  'Так вот, очень важно не просто приукрасить \"стало\", но и специально ухудшить \"было\".',\n",
       "  'Добавить в прошлом лишних кило, кожу состарить, добавить еще чего-нибудь неприятного.',\n",
       "  'Тогда сравнение со \"стало\" будет особо убедительным!',\n",
       "  'Это мне чика одна рассказала.'],\n",
       " ['Из серии секретов, которые знает все телки, а мужики не догадываются.',\n",
       "  'Мужики додумываются только \"стало\" улучшить, а \"было\" испортить не догадываются.',\n",
       "  'Что такое ксенофобия?'],\n",
       " ['Это боязнь незнакомого.'],\n",
       " ['Как бороться с ксенофобией?',\n",
       "  'Делать незнакомое знакомым.',\n",
       "  'Дизайн проще всего воспринимать как борьбу с ксенофобией.',\n",
       "  'Чем узнаваемее, тем менее опасно.',\n",
       "  'Задача большинства брендов - примелькаться и тем самым обозначить неопасность.'],\n",
       " ['Знакомые бренды становятся безопасными, потом различимыми в толпе, а потом даже любимыми.',\n",
       "  'Незнакомые бренды - \"китайское говно\".']]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pars[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't have hyperparameters, so just cluster words in texts\n",
    "all_scores = {\"pk\":[], \"windowdiff\":[]}\n",
    "real_pars = []\n",
    "pred_pars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8c987a2f604f18a7426ec0bb8a16be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing sentences\n",
      "12 15\n",
      "Lemmatizing sentences\n",
      "9 13\n",
      "Lemmatizing sentences\n",
      "8 10\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(text_paths[-3:]):\n",
    "        \n",
    "    (sents, \n",
    "         real_paragraphs, \n",
    "         pred_segment_indices, \n",
    "         pred_paragraphs) = f.segmentize_by_clustering(path, \n",
    "                                                    model=model)\n",
    "        \n",
    "    print(len(real_paragraphs), len(pred_segment_indices))\n",
    "        \n",
    "    k = round(0.5*len(sents)/len(real_paragraphs))\n",
    "    scores = f.evaluate(f.gold_segment_indices(real_paragraphs), pred_segment_indices, k=k)     \n",
    "    \n",
    "        \n",
    "    all_scores[\"pk\"].append(scores[\"pk\"])\n",
    "    all_scores[\"windowdiff\"].append(scores[\"windowdiff\"])\n",
    "    \n",
    "    real_pars.append(real_paragraphs)\n",
    "    pred_pars.append(pred_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pk': [0.41304347826086957, 0.5274725274725275, 0.2777777777777778],\n",
       " 'windowdiff': [0.42391304347826086, 0.5494505494505495, 0.2962962962962963]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4060979278370582"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores[\"pk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42321996307503557"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores[\"windowdiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Пиздец, больше всего на свете меня бесит, что в кино продают треульные начос и круглые банки с сыром.',\n",
       "  'И начос в эту банку залезает только одним уголочком.',\n",
       "  'И ты должен каждый раз откусывать уголок, чтобы начос приобрел более прямоугольную форму и начал в банку с сыром залезать.',\n",
       "  'Вот почему не сделать банки с сыром такой формы, чтобы начос в них сразу было удобно макать?',\n",
       "  'Пиздец, самая большая тупость на свете - это концепция \"здоровой еды\".',\n",
       "  'Епта, если не пить серную кислоту и не заедать ее асбестом, любая еда - здоровая.',\n",
       "  'Когда человек поел, он живет.'],\n",
       " ['Ну а если не будет есть, то в какой-то момент помрет.У каждого поколения есть свои пищевые стереотипы - то надо есть жир, то не надо, то слова надо.',\n",
       "  'Единственное, что точно известно: надо срать на все мнения и есть любую еду.',\n",
       "  'Чем разнообразнее, тем лучше.',\n",
       "  'Нет какого-то одного невероятно полезного продукта.',\n",
       "  'Ягоды годжи не спасут никого, а если их есть каждый день, то еще и заебут.',\n",
       "  'Чипсари с колой вредны только тогда, когда человек не ест ничего другого.',\n",
       "  'Но с таким же успехом можно подорвать здоровье поедая только апельсины с укропом.',\n",
       "  'Поэтому: ешьте что хотите и когда хотите.',\n",
       "  'Главное - разнообразие.'],\n",
       " ['Ну а если пучит от панакоты, то просто не надо ее есть, ок?',\n",
       "  'Интересно изучать административную и политическую карту мира.',\n",
       "  'Скажем, в США почте все штаты тупо разграничены по широтам и долготам.',\n",
       "  'Особенно я люблю штат Колорадо, у которого площадь строго прямоугольная.',\n",
       "  'В Африке половина стран на севере делили пустыню шедрой линейкой, потому что там все равно никогда ничего ценного не будет.',\n",
       "  'В России только граница республики Коми и Ненецкого АО похожа на прямую линию.'],\n",
       " ['О чем нам это говорит?',\n",
       "  'Там, где нихуя нет, границы проведены по линейке.',\n",
       "  'Там, где есть что-то интересное и ценное, границы проведены по рельефу - по горам, по рекам, по каким-то еще ориентирам.',\n",
       "  'Сегодня голосовая связь в мессенджерах лучше, чем в телефоне.',\n",
       "  'Сотовые операторы проебали голос.',\n",
       "  'Пока мировые сотовые компании были заняты рубкой бабла, они забыли, что надо заниматься своей основной услугой.'],\n",
       " ['Ирония в том, что они в какой-то момент поняли, что их основная услуга - это передача данных, а не голоса.',\n",
       "  'И начали улучшать передачу данных.',\n",
       "  'И начали запихивать в ускоренные данные свой старый голос, радуясь прибыли.',\n",
       "  'А мессенджеры научились передавать по каналу данных голос прекрасного качества.',\n",
       "  'И выебали сотовых операторов на их же инфраструктуре.'],\n",
       " ['Одни люди пьют воду с газом.',\n",
       "  'Другие люди пьют воду без газа.',\n",
       "  'А есть третьи люди, которые просят смешать воду с газом и без, чтобы получилась слабогазированная вода.',\n",
       "  'Впрочем, бывает в продаже слабогазированная вода, но я никогда не видел ее ни в одном кафе или ресторане.'],\n",
       " ['Сегодня в мире самая распространенная профессия - водитель.',\n",
       "  'При этом нет никаких сомнений, что в ближайшем будущем водителей практически полностью заменят беспилотные автомобили.',\n",
       "  'А это значит, что всем водителям придется находить себе новые занятия.',\n",
       "  'Конечно, какое-то количество водителей останется, так же как и сегодня в больничных лифтах работают лифтеры, а в жилых домах лифтеров больше не осталось.',\n",
       "  'Так что водителям есть смысл задуматься о том, чем они будут заниматься лет через десять.'],\n",
       " ['Сегодня мобильный телефон - источник невероятного количества личной информации про своего владельца.',\n",
       "  'И это, конечно, прекрасно известно любому ревнивому партнеру.',\n",
       "  'Девочки палят нотификейшены у мальчиков, мальчики подсматривают за алертами у девочек.',\n",
       "  'Все хотят краем глаза увидеть, кто там тебе прислал сообщение в телеге, кто лайкнул фотку в инсте, кто отсыпал сердечек в зенли.'],\n",
       " ['Как узнать - палит ли тебя партнер?',\n",
       "  'Для начала выключаешь телефон.',\n",
       "  'Включаешь его, но не по отпечатку и не рожей, чтобы не залогиниться под собой.',\n",
       "  'Включаешь камеру, выбираешь видео, ставишь фронталку, нажимаешь на запись, кладешь телефон экраном на стол и уходишь в толчок.',\n",
       "  'В этот момент на телефон приходит очередной нотификейшн, вибрация, блямк или любой другой сигнал.',\n",
       "  'Или не приходит, это не принципиально.',\n",
       "  'Ревнивый партнер не выдерживает и хватает аппарат.',\n",
       "  'Смотрит на экран - а там идет запись его подлого подглядывания!',\n",
       "  'Отвертеться не удастся.'],\n",
       " ['Даже если партнер сообразительный и сотрет видос, чтобы поставить на запись новый, в удаленных файлах все сохранится.',\n",
       "  'Сейчас большую популярность приобретает западная теория, что после сранья нужно перед спусканием воды закрывать крышку унитаза.',\n",
       "  'Теория в том, что если крышку не закрыть, то микробы от говна поднимутся в воздух и заразят пространство вокруг.',\n",
       "  'А если закрыть крышку, то микробы ударятся в нее и не полетят дальше.',\n",
       "  'Просто пиздец, как это тупо.'],\n",
       " ['Даже если не закрыть крышку, микробы (согласно научному исследованию) поднимутся на 20 сантиметров над очком.',\n",
       "  'Ну как поднимутся, как и опустятся.',\n",
       "  'А если их задержать крышкой, то они точно осядут на крышке.',\n",
       "  'И каждый, кто сядет потом на унитаз, своей майкой с крышки соберет весь этот урожай.',\n",
       "  'Так что я продолжаю утверждать, что крышка на унитазе примерно так же полезна и нужна, как и на газовой плите.'],\n",
       " ['То есть - абсолютно вообще нахуй не нужна.',\n",
       "  'Я тут узнал, что, оказывается, в мире существует дефицит садистов, но совершенно нет никакого дефицита мазохистов.',\n",
       "  'Проблема везде, даже на соответствующих вечеринках.',\n",
       "  'Все готовы страдать, но мало кто готов мучить.В принципе, это соответствует моему представлению об устройстве мира.',\n",
       "  'Некоторые процессы надо делать иррационально, медленно, вручную, неэффективно, устаревшими способами, немодно, незрелищно и пр. Скажем, для часто повторяющихся операций можно написать скрипт.',\n",
       "  'Но иногда ручной копи-пейст помогает лишний раз подумать, оценить и отловить косяк.'],\n",
       " ['Хотя с точки зрения прогресса делать что-либо руками - неправильно.',\n",
       "  'Можно поставить камеру с распознаванием лиц и поз, но иногда эффективнее посадить бабулю, которая вяжет свой носок и поглядывает на проходящих.',\n",
       "  'Один раз на тыщу случаев бабуля окажется нужной, а камера проебет инцидент.',\n",
       "  'Кстати, именно поэтому я терпеть не могу электрические чайники, микроволновки и кондиционеры - они отбирают у меня последнюю радость получения физического удовольствия от чайника на огне, сковородки и вентилятора.',\n",
       "  'Эффективность не всегда нужна.'],\n",
       " ['Кстати, если бы я был американцем, я бы из этой мысли накатал бы книгу на 400 страниц.',\n",
       "  'Но в этом конкретном случае я как раз за эффективность - мысль понятна и в виде этого небольшого постеца.',\n",
       "  'Прикольно, что в СССР в любом учреждении и магазине был перерыв на обед.'],\n",
       " ['Где с часу до двух, где с двух до трех.',\n",
       "  'А после перестройки перерыв на обед исчез как класс навсегда.',\n",
       "  'Никто не готов прийти к двери учреждения и узнать, что там у работников обед.',\n",
       "  'И эта традиция исчезла безо всяких демонстраций, митингов и протестов.',\n",
       "  'Она просто растворилась, хотя все советские люди были уверены, что ничего более незыблемого на свете нет.',\n",
       "  'Заметил, что когда люди спрашивают друг у друга посоветовать специалиста, всегда прибавляют эпитет \"хороший\".',\n",
       "  'У тебя есть знакомый хороший дантист?',\n",
       "  'Знаешь хорошего автомеханика?',\n",
       "  'Можешь посоветовать хорошего дизайнера?',\n",
       "  'Спрашивается, зачем такое уточнение?',\n",
       "  'Если я прошу посоветовать мне сантехника, разве мне нужен плохой?',\n",
       "  'Или я ищу плохого водителя?',\n",
       "  'Или плохого строителя?',\n",
       "  'Любой человек всегда ищет хороших специалистов.',\n",
       "  'Но зачем уточнять?',\n",
       "  'Попробуйте в следующий раз, когда просите помощи в поиске специалистов у друзей, обойтись без слова \"хороший\".']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMD (Lebedev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9,\n",
       " 0.93,\n",
       " 0.96,\n",
       " 0.99,\n",
       " 1.02,\n",
       " 1.05,\n",
       " 1.08,\n",
       " 1.11,\n",
       " 1.14,\n",
       " 1.17,\n",
       " 1.2,\n",
       " 1.23,\n",
       " 1.26,\n",
       " 1.29,\n",
       " 1.32,\n",
       " 1.35,\n",
       " 1.38,\n",
       " 1.41,\n",
       " 1.44,\n",
       " 1.47,\n",
       " 1.5,\n",
       " 1.53,\n",
       " 1.56,\n",
       " 1.59,\n",
       " 1.62,\n",
       " 1.65,\n",
       " 1.68,\n",
       " 1.71,\n",
       " 1.74,\n",
       " 1.77,\n",
       " 1.8,\n",
       " 1.83,\n",
       " 1.86,\n",
       " 1.89,\n",
       " 1.92,\n",
       " 1.95,\n",
       " 1.98]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_candidates = [round(i,2) for i in list(0.01 * np.arange(90, 200, 3))]\n",
    "tau_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_dict_pk = {i:[] for i in tau_candidates}\n",
    "tau_dict_windowdiff = {i:[] for i in tau_candidates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a6d107ab07455090bf1d3664c7987e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing sentences\n",
      "10 20\n",
      "Lemmatizing sentences\n",
      "10 22\n",
      "Lemmatizing sentences\n",
      "10 22\n",
      "Lemmatizing sentences\n",
      "10 29\n",
      "Lemmatizing sentences\n",
      "10 30\n",
      "Lemmatizing sentences\n",
      "10 30\n",
      "Lemmatizing sentences\n",
      "10 31\n",
      "Lemmatizing sentences\n",
      "10 28\n",
      "Lemmatizing sentences\n",
      "10 30\n",
      "Lemmatizing sentences\n",
      "10 38\n",
      "Lemmatizing sentences\n",
      "10 33\n",
      "Lemmatizing sentences\n",
      "10 28\n",
      "Lemmatizing sentences\n",
      "10 23\n",
      "Lemmatizing sentences\n",
      "10 18\n",
      "Lemmatizing sentences\n",
      "10 15\n",
      "Lemmatizing sentences\n",
      "10 13\n",
      "Lemmatizing sentences\n",
      "10 10\n",
      "Lemmatizing sentences\n",
      "10 4\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "10 1\n",
      "Lemmatizing sentences\n",
      "7 7\n",
      "Lemmatizing sentences\n",
      "7 9\n",
      "Lemmatizing sentences\n",
      "7 9\n",
      "Lemmatizing sentences\n",
      "7 11\n",
      "Lemmatizing sentences\n",
      "7 12\n",
      "Lemmatizing sentences\n",
      "7 12\n",
      "Lemmatizing sentences\n",
      "7 16\n",
      "Lemmatizing sentences\n",
      "7 19\n",
      "Lemmatizing sentences\n",
      "7 23\n",
      "Lemmatizing sentences\n",
      "7 25\n",
      "Lemmatizing sentences\n",
      "7 21\n",
      "Lemmatizing sentences\n",
      "7 19\n",
      "Lemmatizing sentences\n",
      "7 13\n",
      "Lemmatizing sentences\n",
      "7 13\n",
      "Lemmatizing sentences\n",
      "7 8\n",
      "Lemmatizing sentences\n",
      "7 6\n",
      "Lemmatizing sentences\n",
      "7 4\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 1\n",
      "Lemmatizing sentences\n",
      "7 9\n",
      "Lemmatizing sentences\n",
      "7 13\n",
      "Lemmatizing sentences\n",
      "7 15\n",
      "Lemmatizing sentences\n",
      "7 17\n",
      "Lemmatizing sentences\n",
      "7 19\n",
      "Lemmatizing sentences\n",
      "7 21\n",
      "Lemmatizing sentences\n",
      "7 24\n",
      "Lemmatizing sentences\n",
      "7 24\n",
      "Lemmatizing sentences\n",
      "7 20\n",
      "Lemmatizing sentences\n",
      "7 20\n",
      "Lemmatizing sentences\n",
      "7 19\n",
      "Lemmatizing sentences\n",
      "7 13\n",
      "Lemmatizing sentences\n",
      "7 10\n",
      "Lemmatizing sentences\n",
      "7 5\n",
      "Lemmatizing sentences\n",
      "7 4\n",
      "Lemmatizing sentences\n",
      "7 3\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 8\n",
      "Lemmatizing sentences\n",
      "7 8\n",
      "Lemmatizing sentences\n",
      "7 8\n",
      "Lemmatizing sentences\n",
      "7 7\n",
      "Lemmatizing sentences\n",
      "7 10\n",
      "Lemmatizing sentences\n",
      "7 12\n",
      "Lemmatizing sentences\n",
      "7 15\n",
      "Lemmatizing sentences\n",
      "7 19\n",
      "Lemmatizing sentences\n",
      "7 18\n",
      "Lemmatizing sentences\n",
      "7 19\n",
      "Lemmatizing sentences\n",
      "7 15\n",
      "Lemmatizing sentences\n",
      "7 14\n",
      "Lemmatizing sentences\n",
      "7 12\n",
      "Lemmatizing sentences\n",
      "7 11\n",
      "Lemmatizing sentences\n",
      "7 8\n",
      "Lemmatizing sentences\n",
      "7 6\n",
      "Lemmatizing sentences\n",
      "7 5\n",
      "Lemmatizing sentences\n",
      "7 4\n",
      "Lemmatizing sentences\n",
      "7 3\n",
      "Lemmatizing sentences\n",
      "7 3\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n",
      "Lemmatizing sentences\n",
      "7 2\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(text_paths[:-3]):\n",
    "        \n",
    "    for tau in tau_candidates:\n",
    "        \n",
    "        (dists, sents, \n",
    "         real_paragraphs, \n",
    "         pred_segment_indices, \n",
    "         pred_paragraphs) = f.segmentize_bipartite_subgraphs(path, \n",
    "                                                    model=model,\n",
    "                                                    tau=tau,\n",
    "                                                    wmd=True)\n",
    "        \n",
    "        print(len(real_paragraphs), len(pred_segment_indices))\n",
    "        if len(pred_segment_indices) < len(real_paragraphs)/2 or len(pred_segment_indices) > len(real_paragraphs)*2:\n",
    "            continue\n",
    "        \n",
    "        k = round(0.5*len(sents)/len(real_paragraphs))\n",
    "        scores = f.evaluate(f.gold_segment_indices(real_paragraphs), pred_segment_indices, k=k)\n",
    "            \n",
    "        \n",
    "        tau_dict_pk[tau].append(scores[\"pk\"])\n",
    "        tau_dict_windowdiff[tau].append(scores[\"windowdiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9: [0.5825242718446602,\n",
       "  0.43137254901960786,\n",
       "  0.42592592592592593,\n",
       "  0.6304347826086957],\n",
       " 1.29: [0.3883495145631068,\n",
       "  0.43137254901960786,\n",
       "  0.42592592592592593,\n",
       "  0.6086956521739131],\n",
       " 1.32: [0.32038834951456313,\n",
       "  0.39215686274509803,\n",
       "  0.42592592592592593,\n",
       "  0.6086956521739131]}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_dict_pk_short = {k:v for k,v in tau_dict_pk.items() if len(v) == 4}\n",
    "tau_dict_pk_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9: 0.5175643823497225, 1.29: 0.46358591042063846, 1.32: 0.436791697589875}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:np.mean(v) for k,v in tau_dict_pk_short.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9: [0.6893203883495146, 0.49019607843137253, 0.5, 0.6739130434782609],\n",
       " 1.29: [0.5436893203883495,\n",
       "  0.5490196078431373,\n",
       "  0.46296296296296297,\n",
       "  0.7608695652173914],\n",
       " 1.32: [0.46601941747572817,\n",
       "  0.47058823529411764,\n",
       "  0.46296296296296297,\n",
       "  0.6956521739130435]}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_dict_windowdiff_short = {k:v for k,v in tau_dict_windowdiff.items() if len(v) == 4}\n",
    "tau_dict_windowdiff_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9: 0.588357377564787, 1.29: 0.5791353641029603, 1.32: 0.5238056974114631}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:np.mean(v) for k,v in tau_dict_windowdiff_short.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 1.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdffe9f20de34277838e370b108e886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts/lebedev/05.txt\n",
      "Lemmatizing sentences\n",
      "12 10\n",
      "texts/lebedev/06.txt\n",
      "Lemmatizing sentences\n",
      "9 8\n",
      "texts/lebedev/07.txt\n",
      "Lemmatizing sentences\n",
      "8 6\n"
     ]
    }
   ],
   "source": [
    "all_scores = {\"pk\":[], \"windowdiff\":[]}\n",
    "real_pars = []\n",
    "pred_pars = []\n",
    "tau=1.32\n",
    "\n",
    "for path in tqdm(text_paths[-3:]):\n",
    "        \n",
    "    print(path)\n",
    "    (wmd_distances, sents, real_paragraphs, pred_segment_indices, pred_paragraphs) = f.segmentize_bipartite_subgraphs(path, \n",
    "                                                                                                       model=model,\n",
    "                                                                                                        tau=tau,\n",
    "                                                                                                        wmd=True)\n",
    "        \n",
    "    print(len(real_paragraphs), len(pred_segment_indices))\n",
    "        \n",
    "    k = round(0.5*len(sents)/len(real_paragraphs))\n",
    "    scores = f.evaluate(f.gold_segment_indices(real_paragraphs), pred_segment_indices, k=k)     \n",
    "    \n",
    "        \n",
    "    all_scores[\"pk\"].append(scores[\"pk\"])\n",
    "    all_scores[\"windowdiff\"].append(scores[\"windowdiff\"])\n",
    "    \n",
    "    real_pars.append(real_paragraphs)\n",
    "    pred_pars.append(pred_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pk': [0.5543478260869565, 0.6043956043956044, 0.35185185185185186],\n",
       " 'windowdiff': [0.5978260869565217, 0.6153846153846154, 0.4074074074074074]}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5035317607781377"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores[\"pk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5402060365828482"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores[\"windowdiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
